{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://gist.github.com/bwhite/3726239"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Args:\n",
    "    * GT (Ground truth) : NxM sparse matrix, where N is the number of users and M is the number of items\n",
    "    * Pred (Prediction) : an Nxk array of item IDs, ranked by decreasing relevance.\n",
    "    * R: Iterator of relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "            shape: Nxk\n",
    "    * r: relevance scores (list of numpy) in rank order of a specefic query\n",
    "            (first element is the first item)\n",
    "            shape: kx1\n",
    "    where N is the number of queries, and k is the number of recommended items\n",
    "    \n",
    "Note:\n",
    "'R' and 'r' represent both the ground truth (relevance) and the prediction (ranking). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Score is reciprocal of the rank of the first relevant item\n",
    "First element is 'rank 1'. Relevance is binary (nonzero is relevant).\n",
    "\"\"\"\n",
    "def reciprocal_rank(r):\n",
    "    r = np.asarray(r).nonzero()[0]\n",
    "    return 1. / (r[0] + 1) if r.shape[0] else 0.\n",
    "\n",
    "\n",
    "\"\"\" 'batch' makes no sense here.\n",
    "There must be more than one query result that can cmopute mean values.\n",
    "Return a value instead of a list\n",
    "\"\"\"\n",
    "def batch_mean_reciprocal_rank(R):\n",
    "    R = np.asarray(R)\n",
    "    idx = ((R == 0).argmin(1) + 1)\n",
    "    return np.sum(np.where((R == 0).all(axis=1), 0, 1./idx)) / R.shape[0]\n",
    "#     val_line = np.unique(R.nonzero()[0])\n",
    "#     return np.sum(1. / ((R == 0).argmin(1)[val_line]+1)) / R.shape[0]\n",
    "\n",
    "\n",
    "\"\"\"same function as above\"\"\"\n",
    "def mean_reciprocal_rank(R):\n",
    "    R = (np.asarray(r).nonzero()[0] for r in R)\n",
    "    return np.mean([1. / (r[0] + 1) if r.shape[0] else 0. for r in R])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "1.0\n",
      "0.0\n",
      "0.611111111111111\n",
      "0.5\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "r = [0, 0, 0, 1]\n",
    "print(reciprocal_rank(r))  # 0.25\n",
    "\n",
    "r = [1, 0, 0]\n",
    "print(reciprocal_rank(r))  # 1.0\n",
    "\n",
    "r = [0, 0, 0]\n",
    "print(reciprocal_rank(r))  # 0.0\n",
    "\n",
    "rs = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
    "print(batch_mean_reciprocal_rank(rs))  # 0.611111111111111\n",
    "\n",
    "rs = np.array([[0, 0, 0], [0, 1, 0], [1, 0, 0]])\n",
    "print(batch_mean_reciprocal_rank(rs))  # 0.5\n",
    "\n",
    "rs = [[0, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1]]\n",
    "print(batch_mean_reciprocal_rank(rs))  # 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Score is precision @ k\n",
    "Relevance is binary (nonzero is relevant).\n",
    "\"\"\"\n",
    "def precision_at_k(r, k):\n",
    "    assert k >= 1\n",
    "    r = np.asarray(r)[:k] != 0  # true-false values\n",
    "    if r.shape[0] != k:\n",
    "        raise ValueError('Relevance score length < k')  # len(r) must be >= k\n",
    "    return np.mean(r)\n",
    "\n",
    "\n",
    "def batch_precision_at_k(R, k):\n",
    "    assert k >= 1\n",
    "    R = np.asarray(R)[:,:k] != 0\n",
    "    if R.shape[1] != k:\n",
    "        raise ValueError('At least one relevance score length < k')  # len(r) must be >= k\n",
    "    return np.mean(R, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.3333333333333333\n",
      "[0.33333333 0.33333333 0.33333333]\n"
     ]
    }
   ],
   "source": [
    "r = [0, 0, 1]\n",
    "R = [[0, 0, 1],[0, 0, 1], [0, 0, 1]]\n",
    "\n",
    "print(precision_at_k(r, 1))  # 0.0\n",
    "\n",
    "print(precision_at_k(r, 2))  # 0.0\n",
    "\n",
    "print(precision_at_k(r, 3))  # 0.33333333333333331\n",
    "\n",
    "print(batch_precision_at_k(R, 3))  # [0.33333333 0.33333333 0.33333333]\n",
    "\n",
    "# print(precision_at_k(r, 4))  # ValueError: Relevance score length < k\n",
    "\n",
    "# print(batch_precision_at_k(R, 4))  # At least one relevance score length < k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Score is (mean) average precision (area under PR curve)\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "\"\"\"\n",
    "def average_precision(r):\n",
    "    r = np.asarray(r) != 0\n",
    "    mask = np.tril(np.ones(r.shape[0]))\n",
    "    out = (r * mask * np.tile(r, (r.shape[0], 1)).transpose()).sum(1)\n",
    "    c = (out != 0).sum()\n",
    "    if not c:\n",
    "        return 0.\n",
    "    return (out / mask.sum(1)).sum() / c\n",
    "\n",
    "# def average_precision(r):\n",
    "#     r = np.asarray(r) != 0\n",
    "#     out = [precision_at_k(r, k + 1) for k in range(r.shape[0]) if r[k]]  # r*mask/sum_of_mask\n",
    "#     if not out:\n",
    "#         return 0.\n",
    "#     return np.mean(out)\n",
    "\n",
    "\n",
    "\"\"\" 'batch' makes no sense here.\n",
    "There must be more than one query result that can cmopute mean values.\n",
    "Return a value instead of a list\n",
    "\"\"\"\n",
    "def batch_mean_average_precision(R):  # GT  Suppress=True: if False, /GT. True: min(m, k)\n",
    "    R = np.asarray(R) != 0\n",
    "    R = np.repeat(R[:, :, np.newaxis], R.shape[1], axis=2)\n",
    "    mask = np.tril(np.ones(R.shape[1]))\n",
    "    mask = np.repeat(mask[np.newaxis, :], R.shape[0], axis=0)\n",
    "    out = (R.transpose((0, 2, 1)) * mask * R).sum(2)\n",
    "    c = (out != 0).sum(1)\n",
    "    a = (out / mask.sum(2)).sum(1)\n",
    "    return np.divide(a, c, np.zeros_like(a), where = c != 0).mean()\n",
    "\n",
    "# how many items in GT\n",
    "# Nxk (sparse matrix)\n",
    "\n",
    "\n",
    "\"\"\"same function as above\"\"\"\n",
    "def mean_average_precision(R):\n",
    "    return np.mean([average_precision(r) for r in R])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.7833333333333333\n",
      "0.7833333333333333\n",
      "0.7833333333333333\n",
      "0.39166666666666666\n"
     ]
    }
   ],
   "source": [
    "r = [0, 0, 0, 0, 0]\n",
    "print(average_precision(r))  # 0.0\n",
    "\n",
    "r = [1, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
    "print(average_precision(r))  # 0.78333333333333333\n",
    "\n",
    "R = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1]]\n",
    "print(batch_mean_average_precision(R))  # 0.78333333333333333\n",
    "\n",
    "R = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1], [1, 1, 0, 1, 0, 1, 0, 0, 0, 1]]\n",
    "print(batch_mean_average_precision(R))  # 0.78333333333333333\n",
    "\n",
    "R = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "print(batch_mean_average_precision(R))  # 0.39166666666666666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Score is discounted cumulative gain (dcg)\n",
    "Relevance is positive real values.  \n",
    "Can use binary as the previous methods.\n",
    "\n",
    "method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "        If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "\"\"\"\n",
    "def dcg_at_k(r, k, method=0):\n",
    "    r = np.asfarray(r)[:k]  # turn to float\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.shape[0] + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def batch_dcg_at_k(R, k, method=0):\n",
    "    R = np.asfarray(R)[:,:k]\n",
    "    N = R.size\n",
    "    if N and R[0].size:\n",
    "        if method == 0:\n",
    "            return R[:,0] + np.sum(R[:,1:] / np.log2(np.arange(2, R[0].size + 1)), axis=1)\n",
    "        elif method == 1:\n",
    "            return np.sum(R / np.log2(np.arange(2, R[0].size + 2)), axis=1)\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1')\n",
    "    return np.zeros(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
    "Relevance is positive real values.  \n",
    "Can use binary as the previous methods.\n",
    "\n",
    "method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "        If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "\"\"\"\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max\n",
    "\n",
    "\n",
    "def b_ndcg_at_k(R, k, method=0):\n",
    "    return [ndcg_at_k(r, k, method) for r in R]\n",
    "\n",
    "def batch_ndcg_at_k(R, k, method=0):\n",
    "    R = np.asarray(R)\n",
    "    batch_dcg_max = batch_dcg_at_k(np.take_along_axis(R, np.argsort(-R, axis=1), axis=1), k, method)\n",
    "    batch_dcg_max = np.where(batch_dcg_max == 0., 1e-5, batch_dcg_max)\n",
    "    return np.where(batch_dcg_max == 0., 0., batch_dcg_at_k(R, k, method) / batch_dcg_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.3187531 8.3187531 8.3187531]\n",
      "8.318753101481006\n"
     ]
    }
   ],
   "source": [
    "R = [[3, 2, 3, 0, 0, 1, 2, 2, 3, 0],[3, 2, 3, 0, 0, 1, 2, 2, 3, 0],[3, 2, 3, 0, 0, 1, 2, 2, 3, 0]]\n",
    "R = np.array(R)\n",
    "a = batch_dcg_at_k(R, 10, method=1)\n",
    "r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "b = dcg_at_k(r, 10, method=1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91680888 0.91680888 0.        ]\n",
      "0.9168088790321769\n"
     ]
    }
   ],
   "source": [
    "R = [[3, 2, 3, 0, 0, 1, 2, 2, 3, 0],[3, 2, 3, 0, 0, 1, 2, 2, 3, 0],[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "R = np.array(R)\n",
    "a = batch_ndcg_at_k(R, 10, method=1)\n",
    "r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "b = ndcg_at_k(r, 10, method=1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------reciprocal rank---------\n",
      "benchmark:\n",
      "3.65 s ± 104 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "optimized:\n",
      "158 ms ± 6.35 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "---------mean average precision---------\n",
      "benchmark:\n",
      "1min 23s ± 655 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "optimized:\n",
      "60.9 µs ± 525 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "\n",
      "---------mean average precision---------\n",
      "benchmark:\n",
      "140 µs ± 4.04 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "optimized:\n",
      "59.5 µs ± 2.68 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "\n",
      "---------nDCG at k---------\n",
      "benchmark:\n",
      "63.5 µs ± 2.96 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "optimized:\n",
      "54.3 µs ± 3.4 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "test = np.random.randint(0,2,(1000000,100))\n",
    "k = 1000000\n",
    "\n",
    "print('---------reciprocal rank---------')\n",
    "print('benchmark:')\n",
    "%timeit mean_reciprocal_rank(test)\n",
    "print('optimized:')\n",
    "%timeit batch_mean_reciprocal_rank(test)\n",
    "    \n",
    "print('\\n---------mean average precision---------')\n",
    "print('benchmark:')\n",
    "%timeit mean_average_precision(test)\n",
    "print('optimized:')\n",
    "%timeit batch_mean_average_precision(R)\n",
    "    \n",
    "print('\\n---------mean average precision---------')\n",
    "print('benchmark:')\n",
    "%timeit mean_average_precision(R)\n",
    "print('optimized:')\n",
    "%timeit batch_mean_average_precision(R)\n",
    "\n",
    "print('\\n---------nDCG at k---------')\n",
    "print('benchmark:')\n",
    "%timeit b_ndcg_at_k(R, k)\n",
    "print('optimized:') \n",
    "%timeit batch_ndcg_at_k(R, k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
