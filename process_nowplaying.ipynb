{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Context attributes:\n",
    "user_id,\n",
    "track_id,instrumentalness,liveness,speechiness,danceability,valence,loudness,tempo,acousticness,energy,mode,key,\n",
    "hashtag,created_at,score,lang,tweet_lang,time_zone,rating\n",
    "\n",
    "shape:\n",
    "3,613,460 ratings (listing events)\n",
    "4,776   users\n",
    "22,092  items (tracks)\n",
    "\n",
    "The author used the timestamps to split #nowplaying- RS into the training (from Jan. 1 to Sep. 30) and test sets (from Nov. 1 to Dec. 23). \n",
    "To be consistent with movielens, this code combines train and test dataset, then split it into train, validation, and test with the same method\n",
    "------- not sure if it is necessary\n",
    "\n",
    "Users who have listened to less than 10 tracks and tracks which have been listened to by less than 10 users are already removed\n",
    "LEs that do not contain hashtags or do not exhibit any sentiment information from the dataset for the experiments are removed as well\n",
    "\n",
    "There are only positive examples in original datasets.\n",
    "To create negative samples, please follow https://github.com/asmitapoddar/nowplaying-RS-Music-Reco-FM/tree/6ab9e65f2c08e6c5733ba40d9f84b3dfa2671fd5 \n",
    "For each listening event, add nine tracks as the negative samples. \n",
    "\n",
    "Use random population (POP_RND), where we added nine randomly chosen tracks that the user has not listened to previously.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import argparse\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as ssp\n",
    "import dgl\n",
    "import torch\n",
    "import torchtext\n",
    "from builder import PandasGraphBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'Datasets/nowplaying-rs/Context'\n",
    "output_path = '/Users/helinfan/Desktop/dataprocessing/result.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =  pd.read_csv(\"Datasets/nowplaying-rs/Context/train_final_POP_RND.txt\",sep='\\t',header=None,index_col=False,\n",
    "                  names=['user_id', 'track_id', 'hashtag', 'created_at', 'score', 'lang','tweet_lang', \\\n",
    "                         'time_zone','instrumentalness', 'liveness','speechiness', 'danceability', 'valence', \\\n",
    "                         'loudness', 'tempo','acousticness', 'energy', 'mode', 'key', 'rating'])\n",
    "\n",
    "test =  pd.read_csv(\"Datasets/nowplaying-rs/Context/test_final_POP_RND.txt\",sep='\\t',header=None,index_col=False,\n",
    "                  names=['user_id', 'track_id', 'hashtag', 'created_at', 'score', 'lang','tweet_lang', \\\n",
    "                         'time_zone','instrumentalness', 'liveness','speechiness', 'danceability', 'valence', \\\n",
    "                         'loudness', 'tempo','acousticness', 'energy', 'mode', 'key', 'rating'])\n",
    "\n",
    "df = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.DataFrame(df['user_id']).astype('category').drop_duplicates()\n",
    "\n",
    "tracks = train.drop(['user_id', 'hashtag', 'created_at', 'score', 'lang', 'tweet_lang', \\\n",
    "                           'time_zone', 'rating'], axis=1).drop_duplicates()\n",
    "tracks = pd.DataFrame(tracks).astype({'key': 'category'})\n",
    "\n",
    "ratings = train.drop(['instrumentalness','liveness','speechiness','danceability', \\\n",
    "                            'valence','loudness','tempo','acousticness','energy','mode','key'],axis=1)\n",
    "ratings = pd.DataFrame(ratings).astype({'hashtag': 'category', 'lang': 'category', 'tweet_lang': 'category', 'time_zone': 'category'})\n",
    "ratings['created_at'] = pd.to_datetime(ratings['created_at'],format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "genre_columns = tracks.columns.drop(['track_id', 'key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = PandasGraphBuilder()\n",
    "graph_builder.add_entities(users, 'user_id', 'user')\n",
    "graph_builder.add_entities(tracks, 'track_id', 'track')\n",
    "graph_builder.add_binary_relations(ratings, 'user_id', 'track_id', 'listened')\n",
    "graph_builder.add_binary_relations(ratings, 'track_id', 'user_id', 'listened-by')\n",
    "\n",
    "g = graph_builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign features.\n",
    "# Note that variable-sized features such as texts or images are handled elsewhere.\n",
    "# g.nodes['user'].data['gender'] = torch.LongTensor(users['gender'].cat.codes.values)\n",
    "# g.nodes['user'].data['age'] = torch.LongTensor(users['age'].cat.codes.values)\n",
    "# g.nodes['user'].data['occupation'] = torch.LongTensor(users['occupation'].cat.codes.values)\n",
    "# g.nodes['user'].data['zip'] = torch.LongTensor(users['zip'].cat.codes.values)\n",
    "\n",
    "g.nodes['track'].data['key'] = torch.LongTensor(tracks['key'].cat.codes.values)\n",
    "g.nodes['track'].data['genre'] = torch.FloatTensor(tracks[genre_columns].values)\n",
    "\n",
    "g.edges['listened'].data['hashtag'] = torch.LongTensor(ratings['hashtag'].cat.codes.values)\n",
    "g.edges['listened'].data['created_at'] = torch.FloatTensor(ratings['created_at'].values.astype('int64') / 1000000000)\n",
    "g.edges['listened'].data['score'] = torch.FloatTensor(ratings['score'].values)\n",
    "g.edges['listened'].data['lang'] = torch.LongTensor(ratings['lang'].cat.codes.values)\n",
    "g.edges['listened'].data['tweet_lang'] = torch.LongTensor(ratings['tweet_lang'].cat.codes.values)\n",
    "g.edges['listened'].data['time_zone'] = torch.LongTensor(ratings['time_zone'].cat.codes.values)\n",
    "g.edges['listened'].data['rating'] = torch.LongTensor(ratings['rating'].values)\n",
    "\n",
    "g.edges['listened-by'].data['hashtag'] = torch.LongTensor(ratings['hashtag'].cat.codes.values)\n",
    "g.edges['listened-by'].data['created_at'] = torch.FloatTensor(ratings['created_at'].values.astype('int64'))\n",
    "g.edges['listened-by'].data['score'] = torch.LongTensor(ratings['score'].values)\n",
    "g.edges['listened-by'].data['lang'] = torch.LongTensor(ratings['lang'].cat.codes.values)\n",
    "g.edges['listened-by'].data['tweet_lang'] = torch.LongTensor(ratings['tweet_lang'].cat.codes.values)\n",
    "g.edges['listened-by'].data['time_zone'] = torch.LongTensor(ratings['time_zone'].cat.codes.values)\n",
    "g.edges['listened-by'].data['rating'] = torch.LongTensor(ratings['rating'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-validation-test split\n",
    "# This is a little bit tricky as we want to select the last interaction for test, and the\n",
    "# second-to-last interaction for validation, except that the \n",
    "n_edges = g.number_of_edges('listened')\n",
    "with g.local_scope():\n",
    "    def splits(edges):\n",
    "        num_edges, count = edges.data['train_mask'].shape\n",
    "\n",
    "        # sort by timestamp\n",
    "        _, sorted_idx = edges.data['created_at'].sort(1)\n",
    "\n",
    "        train_mask = edges.data['train_mask']\n",
    "        val_mask = edges.data['val_mask']\n",
    "        test_mask = edges.data['test_mask']\n",
    "\n",
    "        x = torch.arange(num_edges)\n",
    "\n",
    "        # If one user has more than one interactions, select the latest one for test.\n",
    "        if count > 1:\n",
    "            train_mask[x, sorted_idx[:, -1]] = False\n",
    "            test_mask[x, sorted_idx[:, -1]] = True\n",
    "        # If one user has more than two interactions, select the second latest one for validation.\n",
    "        if count > 2:\n",
    "            train_mask[x, sorted_idx[:, -2]] = False\n",
    "            val_mask[x, sorted_idx[:, -2]] = True\n",
    "        return {'train_mask': train_mask, 'val_mask': val_mask, 'test_mask': test_mask}\n",
    "\n",
    "    g.edges['listened'].data['train_mask'] = torch.ones(n_edges, dtype=torch.bool)\n",
    "    g.edges['listened'].data['val_mask'] = torch.zeros(n_edges, dtype=torch.bool)\n",
    "    g.edges['listened'].data['test_mask'] = torch.zeros(n_edges, dtype=torch.bool)\n",
    "    g.nodes['track'].data['count'] = g.in_degrees(etype='listened')\n",
    "    g.group_apply_edges('src', splits, etype='listened')\n",
    "\n",
    "    train_indices = g.filter_edges(lambda edges: edges.data['train_mask'], etype='listened')\n",
    "    val_indices = g.filter_edges(lambda edges: edges.data['val_mask'], etype='listened')\n",
    "    test_indices = g.filter_edges(lambda edges: edges.data['test_mask'], etype='listened')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph with training interactions only.\n",
    "train_g = g.edge_subgraph(\n",
    "    {'listened': train_indices, 'listened-by': train_indices},\n",
    "    preserve_nodes=True)\n",
    "del train_g.nodes['track'].data[dgl.NID]      # remove the induced node IDs - should be assigned by model instead\n",
    "del train_g.nodes['user'].data[dgl.NID]       # remove the induced user IDs - shoule be assigned by model instead\n",
    "for ntype in g.ntypes:\n",
    "    for col, data in g.nodes[ntype].data.items():\n",
    "        train_g.nodes[ntype].data[col] = data\n",
    "for etype in g.etypes:\n",
    "    for col, data in g.edges[etype].data.items():\n",
    "        train_g.edges[etype].data[col] = data[train_g.edges[etype].data[dgl.EID]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the user-item sparse matrix for validation and test set.\n",
    "n_users = g.number_of_nodes('user')\n",
    "n_items = g.number_of_nodes('track')\n",
    "val_src, val_dst = g.find_edges(val_indices, etype='listened')\n",
    "test_src, test_dst = g.find_edges(test_indices, etype='listened')\n",
    "val_src = val_src.numpy()\n",
    "val_dst = val_dst.numpy()\n",
    "test_src = test_src.numpy()\n",
    "test_dst = test_dst.numpy()\n",
    "val_matrix = ssp.coo_matrix((np.ones_like(val_src), (val_src, val_dst)), (n_users, n_items))\n",
    "test_matrix = ssp.coo_matrix((np.ones_like(test_src), (test_src, test_dst)), (n_users, n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build title set\n",
    "\n",
    "# movie_textual_dataset = {'title': movies['title'].values}\n",
    "\n",
    "# The model should build their own vocabulary and process the texts.  Here is one example\n",
    "# of using torchtext to pad and numericalize a batch of strings.\n",
    "#     field = torchtext.data.Field(include_lengths=True, lower=True, batch_first=True)\n",
    "#     examples = [torchtext.data.Example.fromlist([t], [('title', title_field)]) for t in texts]\n",
    "#     titleset = torchtext.data.Dataset(examples, [('title', title_field)])\n",
    "#     field.build_vocab(titleset.title, vectors='fasttext.simple.300d')\n",
    "#     token_ids, lengths = field.process([examples[0].title, examples[1].title])\n",
    "\n",
    "## Dump the graph and the datasets\n",
    "\n",
    "dataset = {\n",
    "    'train-graph': train_g,\n",
    "    'val-matrix': val_matrix,\n",
    "    'test-matrix': test_matrix,\n",
    "    'item-texts': None,\n",
    "    'item-images': None,\n",
    "    'user-type': 'user',\n",
    "    'item-type': 'track',\n",
    "    'user-to-item-type': 'listened',\n",
    "    'item-to-user-type': 'listened-by',\n",
    "    'timestamp-edge-column': 'created_at'}\n",
    "\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
